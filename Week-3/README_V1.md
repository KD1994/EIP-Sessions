## EIP-4 Week-3

## Training Accuracy ~ 91.5%

## Test Accuracy 	   ~ 83.24%

## Baseline Model Logs

```
390/390 [==============================] - 10s 26ms/step - loss: 1.9611 - acc: 0.2466 - val_loss: 1.5215 - val_acc: 0.4347
Epoch 2/50
390/390 [==============================] - 7s 18ms/step - loss: 1.4296 - acc: 0.4775 - val_loss: 1.1909 - val_acc: 0.5578
Epoch 3/50
390/390 [==============================] - 7s 18ms/step - loss: 1.1999 - acc: 0.5697 - val_loss: 1.0086 - val_acc: 0.6366
Epoch 4/50
390/390 [==============================] - 7s 18ms/step - loss: 1.0592 - acc: 0.6270 - val_loss: 0.8966 - val_acc: 0.6893
Epoch 5/50
390/390 [==============================] - 7s 18ms/step - loss: 0.9352 - acc: 0.6750 - val_loss: 0.8339 - val_acc: 0.7113
Epoch 6/50
390/390 [==============================] - 7s 18ms/step - loss: 0.8604 - acc: 0.7037 - val_loss: 0.7637 - val_acc: 0.7350
Epoch 7/50
390/390 [==============================] - 7s 18ms/step - loss: 0.8071 - acc: 0.7223 - val_loss: 0.7241 - val_acc: 0.7524
Epoch 8/50
390/390 [==============================] - 7s 18ms/step - loss: 0.7593 - acc: 0.7422 - val_loss: 0.7037 - val_acc: 0.7610
Epoch 9/50
390/390 [==============================] - 7s 18ms/step - loss: 0.7244 - acc: 0.7505 - val_loss: 0.6604 - val_acc: 0.7738
Epoch 10/50
390/390 [==============================] - 7s 18ms/step - loss: 0.6843 - acc: 0.7672 - val_loss: 0.6334 - val_acc: 0.7835
Epoch 11/50
390/390 [==============================] - 7s 18ms/step - loss: 0.6551 - acc: 0.7767 - val_loss: 0.6628 - val_acc: 0.7741
Epoch 12/50
390/390 [==============================] - 7s 18ms/step - loss: 0.6325 - acc: 0.7853 - val_loss: 0.6239 - val_acc: 0.7841
Epoch 13/50
390/390 [==============================] - 7s 18ms/step - loss: 0.6240 - acc: 0.7890 - val_loss: 0.5980 - val_acc: 0.7957
Epoch 14/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5967 - acc: 0.7966 - val_loss: 0.6128 - val_acc: 0.7931
Epoch 15/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5736 - acc: 0.8041 - val_loss: 0.6014 - val_acc: 0.7969
Epoch 16/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5586 - acc: 0.8078 - val_loss: 0.5774 - val_acc: 0.8050
Epoch 17/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5402 - acc: 0.8159 - val_loss: 0.5757 - val_acc: 0.8046
Epoch 18/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5394 - acc: 0.8164 - val_loss: 0.5808 - val_acc: 0.8069
Epoch 19/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5312 - acc: 0.8206 - val_loss: 0.5708 - val_acc: 0.8134
Epoch 20/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5135 - acc: 0.8232 - val_loss: 0.5670 - val_acc: 0.8113
Epoch 21/50
390/390 [==============================] - 7s 18ms/step - loss: 0.5007 - acc: 0.8299 - val_loss: 0.5767 - val_acc: 0.8078
Epoch 22/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4920 - acc: 0.8329 - val_loss: 0.5891 - val_acc: 0.8065
Epoch 23/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4784 - acc: 0.8378 - val_loss: 0.5996 - val_acc: 0.8071
Epoch 24/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4746 - acc: 0.8372 - val_loss: 0.5595 - val_acc: 0.8142
Epoch 25/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4658 - acc: 0.8423 - val_loss: 0.5681 - val_acc: 0.8131
Epoch 26/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4504 - acc: 0.8470 - val_loss: 0.5805 - val_acc: 0.8147
Epoch 27/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4492 - acc: 0.8480 - val_loss: 0.5863 - val_acc: 0.8114
Epoch 28/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4438 - acc: 0.8500 - val_loss: 0.5885 - val_acc: 0.8149
Epoch 29/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4402 - acc: 0.8511 - val_loss: 0.5621 - val_acc: 0.8178
Epoch 30/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4312 - acc: 0.8531 - val_loss: 0.5567 - val_acc: 0.8192
Epoch 31/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4293 - acc: 0.8525 - val_loss: 0.5654 - val_acc: 0.8190
Epoch 32/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4173 - acc: 0.8604 - val_loss: 0.5705 - val_acc: 0.8172
Epoch 33/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4099 - acc: 0.8612 - val_loss: 0.5904 - val_acc: 0.8099
Epoch 34/50
390/390 [==============================] - 7s 18ms/step - loss: 0.4048 - acc: 0.8633 - val_loss: 0.5760 - val_acc: 0.8207
Epoch 35/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3993 - acc: 0.8652 - val_loss: 0.5774 - val_acc: 0.8221
Epoch 36/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3885 - acc: 0.8694 - val_loss: 0.5581 - val_acc: 0.8169
Epoch 37/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3980 - acc: 0.8651 - val_loss: 0.5620 - val_acc: 0.8235
Epoch 38/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3902 - acc: 0.8687 - val_loss: 0.5716 - val_acc: 0.8211
Epoch 39/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3871 - acc: 0.8682 - val_loss: 0.5538 - val_acc: 0.8282
Epoch 40/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3823 - acc: 0.8705 - val_loss: 0.5636 - val_acc: 0.8191
Epoch 41/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3819 - acc: 0.8735 - val_loss: 0.5775 - val_acc: 0.8211
Epoch 42/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3665 - acc: 0.8754 - val_loss: 0.5781 - val_acc: 0.8199
Epoch 43/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3650 - acc: 0.8781 - val_loss: 0.5952 - val_acc: 0.8188
Epoch 44/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3552 - acc: 0.8789 - val_loss: 0.5714 - val_acc: 0.8252
Epoch 45/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3649 - acc: 0.8778 - val_loss: 0.5933 - val_acc: 0.8223
Epoch 46/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3590 - acc: 0.8781 - val_loss: 0.5747 - val_acc: 0.8249
Epoch 47/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3590 - acc: 0.8795 - val_loss: 0.5658 - val_acc: 0.8250
Epoch 48/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3421 - acc: 0.8845 - val_loss: 0.6013 - val_acc: 0.8208
Epoch 49/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3454 - acc: 0.8853 - val_loss: 0.6044 - val_acc: 0.8145
Epoch 50/50
390/390 [==============================] - 7s 18ms/step - loss: 0.3454 - acc: 0.8860 - val_loss: 0.5617 - val_acc: 0.8265
Model took 354.44 seconds to train
```
## Target Accuracy > 82.6 %

## Model with Depthwise Separable Convolution
```
model2 = Sequential()

model2.add(SeparableConv2D(32, 3, padding='same', depth_multiplier=2, activation='relu', use_bias=False, input_shape=(32, 32, 3))) #32  RF --> 3
model2.add(BatchNormalization())

model2.add(SeparableConv2D(64, 3, padding='valid', activation='relu', use_bias=False)) # 30  RF --> 5
model2.add(BatchNormalization())
model2.add(Dropout(0.05))

model2.add(SeparableConv2D(128, 3, padding='same', depth_multiplier=2, activation='relu', use_bias=False)) # 30  RF --> 7
model2.add(BatchNormalization())
model2.add(Dropout(0.1))

model2.add(SeparableConv2D(32, 1, padding='same', activation='relu', use_bias=False)) # 30  RF --> 7
model2.add(MaxPooling2D()) # 15  RF --> 8

model2.add(SeparableConv2D(64, 3, padding='same', activation='relu', use_bias=False)) # 15  RF --> 12
model2.add(BatchNormalization())
model2.add(Dropout(0.05))

model2.add(SeparableConv2D(64, 3, padding='same', depth_multiplier=1, activation='relu', use_bias=False)) # 15  RF --> 16
model2.add(BatchNormalization())
model2.add(Dropout(0.1))

model2.add(SeparableConv2D(128, 3, padding='valid', activation='relu', use_bias=False)) # 13  RF --> 20
model2.add(BatchNormalization())
model2.add(Dropout(0.05))

model2.add(SeparableConv2D(128, 3, padding='valid', depth_multiplier=1, activation='relu', use_bias=False)) # 11  RF --> 24
model2.add(BatchNormalization())
model2.add(Dropout(0.1))

model2.add(SeparableConv2D(32, 1, padding='same', activation='relu', use_bias=False)) # 11  RF --> 24
model2.add(MaxPooling2D()) # 5  RF --> 26

model2.add(SeparableConv2D(64, 3, padding='valid', depth_multiplier=2, activation='relu', use_bias=False)) # 3  RF --> 34
model2.add(BatchNormalization())
model2.add(Dropout(0.05))

model2.add(SeparableConv2D(10, 1, padding='same', activation='relu', use_bias=False)) # 3   RF --> 34
model2.add(SeparableConv2D(10, 3, activation='relu', use_bias=False)) # 1  RF --> 42

model2.add(Flatten())
model2.add(Activation('softmax'))

model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

## Summary

```
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
separable_conv2d_1 (Separabl (None, 32, 32, 32)        246       
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128       
_________________________________________________________________
separable_conv2d_2 (Separabl (None, 30, 30, 64)        2336      
_________________________________________________________________
batch_normalization_2 (Batch (None, 30, 30, 64)        256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 30, 30, 64)        0         
_________________________________________________________________
separable_conv2d_3 (Separabl (None, 30, 30, 128)       17536     
_________________________________________________________________
batch_normalization_3 (Batch (None, 30, 30, 128)       512       
_________________________________________________________________
dropout_2 (Dropout)          (None, 30, 30, 128)       0         
_________________________________________________________________
separable_conv2d_4 (Separabl (None, 30, 30, 32)        4224      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
separable_conv2d_5 (Separabl (None, 15, 15, 64)        2336      
_________________________________________________________________
batch_normalization_4 (Batch (None, 15, 15, 64)        256       
_________________________________________________________________
dropout_3 (Dropout)          (None, 15, 15, 64)        0         
_________________________________________________________________
separable_conv2d_6 (Separabl (None, 15, 15, 64)        4672      
_________________________________________________________________
batch_normalization_5 (Batch (None, 15, 15, 64)        256       
_________________________________________________________________
dropout_4 (Dropout)          (None, 15, 15, 64)        0         
_________________________________________________________________
separable_conv2d_7 (Separabl (None, 13, 13, 128)       8768      
_________________________________________________________________
batch_normalization_6 (Batch (None, 13, 13, 128)       512       
_________________________________________________________________
dropout_5 (Dropout)          (None, 13, 13, 128)       0         
_________________________________________________________________
separable_conv2d_8 (Separabl (None, 11, 11, 128)       17536     
_________________________________________________________________
batch_normalization_7 (Batch (None, 11, 11, 128)       512       
_________________________________________________________________
dropout_6 (Dropout)          (None, 11, 11, 128)       0         
_________________________________________________________________
separable_conv2d_9 (Separabl (None, 11, 11, 32)        4224      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         
_________________________________________________________________
separable_conv2d_10 (Separab (None, 3, 3, 64)          4672      
_________________________________________________________________
batch_normalization_8 (Batch (None, 3, 3, 64)          256       
_________________________________________________________________
dropout_7 (Dropout)          (None, 3, 3, 64)          0         
_________________________________________________________________
separable_conv2d_11 (Separab (None, 3, 3, 10)          704       
_________________________________________________________________
separable_conv2d_12 (Separab (None, 1, 1, 10)          190       
_________________________________________________________________
flatten_1 (Flatten)          (None, 10)                0         
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 70,132
Trainable params: 68,788
Non-trainable params: 1,344
_________________________________________________________________
```


## Logs
```
Epoch 1/50
390/390 [==============================] - 32s 83ms/step - loss: 1.7546 - acc: 0.3659 - val_loss: 1.5890 - val_acc: 0.4776

Epoch 00001: val_acc improved from -inf to 0.47760, saving model to /content/best_weights.hdf5
Epoch 2/50
390/390 [==============================] - 30s 76ms/step - loss: 1.1866 - acc: 0.5871 - val_loss: 1.4148 - val_acc: 0.5595

Epoch 00002: val_acc improved from 0.47760 to 0.55950, saving model to /content/best_weights.hdf5
Epoch 3/50
390/390 [==============================] - 30s 76ms/step - loss: 0.8988 - acc: 0.6830 - val_loss: 1.0163 - val_acc: 0.6613

Epoch 00003: val_acc improved from 0.55950 to 0.66130, saving model to /content/best_weights.hdf5
Epoch 4/50
390/390 [==============================] - 30s 76ms/step - loss: 0.7791 - acc: 0.7259 - val_loss: 0.8604 - val_acc: 0.7019

Epoch 00004: val_acc improved from 0.66130 to 0.70190, saving model to /content/best_weights.hdf5
Epoch 5/50
390/390 [==============================] - 30s 76ms/step - loss: 0.7075 - acc: 0.7535 - val_loss: 0.8136 - val_acc: 0.7279

Epoch 00005: val_acc improved from 0.70190 to 0.72790, saving model to /content/best_weights.hdf5
Epoch 6/50
390/390 [==============================] - 29s 76ms/step - loss: 0.6553 - acc: 0.7723 - val_loss: 0.7628 - val_acc: 0.7391

Epoch 00006: val_acc improved from 0.72790 to 0.73910, saving model to /content/best_weights.hdf5
Epoch 7/50
390/390 [==============================] - 30s 76ms/step - loss: 0.6200 - acc: 0.7841 - val_loss: 0.7517 - val_acc: 0.7493

Epoch 00007: val_acc improved from 0.73910 to 0.74930, saving model to /content/best_weights.hdf5
Epoch 8/50
390/390 [==============================] - 30s 76ms/step - loss: 0.5829 - acc: 0.7976 - val_loss: 0.7312 - val_acc: 0.7540

Epoch 00008: val_acc improved from 0.74930 to 0.75400, saving model to /content/best_weights.hdf5
Epoch 9/50
390/390 [==============================] - 30s 76ms/step - loss: 0.5592 - acc: 0.8055 - val_loss: 0.6756 - val_acc: 0.7713

Epoch 00009: val_acc improved from 0.75400 to 0.77130, saving model to /content/best_weights.hdf5
Epoch 10/50
390/390 [==============================] - 30s 76ms/step - loss: 0.5307 - acc: 0.8165 - val_loss: 0.7462 - val_acc: 0.7502

Epoch 00010: val_acc did not improve from 0.77130
Epoch 11/50
390/390 [==============================] - 29s 76ms/step - loss: 0.5022 - acc: 0.8236 - val_loss: 0.7359 - val_acc: 0.7564

Epoch 00011: val_acc did not improve from 0.77130
Epoch 12/50
390/390 [==============================] - 30s 76ms/step - loss: 0.4929 - acc: 0.8281 - val_loss: 0.6597 - val_acc: 0.7801

Epoch 00012: val_acc improved from 0.77130 to 0.78010, saving model to /content/best_weights.hdf5
Epoch 13/50
390/390 [==============================] - 30s 76ms/step - loss: 0.4730 - acc: 0.8354 - val_loss: 0.6500 - val_acc: 0.7920

Epoch 00013: val_acc improved from 0.78010 to 0.79200, saving model to /content/best_weights.hdf5
Epoch 14/50
390/390 [==============================] - 29s 76ms/step - loss: 0.4558 - acc: 0.8413 - val_loss: 0.6848 - val_acc: 0.7730

Epoch 00014: val_acc did not improve from 0.79200
Epoch 15/50
390/390 [==============================] - 30s 76ms/step - loss: 0.4417 - acc: 0.8467 - val_loss: 0.7665 - val_acc: 0.7615

Epoch 00015: val_acc did not improve from 0.79200
Epoch 16/50
390/390 [==============================] - 29s 76ms/step - loss: 0.4262 - acc: 0.8517 - val_loss: 0.5722 - val_acc: 0.8129

Epoch 00016: val_acc improved from 0.79200 to 0.81290, saving model to /content/best_weights.hdf5
Epoch 17/50
390/390 [==============================] - 30s 76ms/step - loss: 0.4174 - acc: 0.8544 - val_loss: 0.6771 - val_acc: 0.7785

Epoch 00017: val_acc did not improve from 0.81290
Epoch 18/50
390/390 [==============================] - 30s 76ms/step - loss: 0.4033 - acc: 0.8587 - val_loss: 0.7395 - val_acc: 0.7734

Epoch 00018: val_acc did not improve from 0.81290
Epoch 19/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3939 - acc: 0.8609 - val_loss: 0.6407 - val_acc: 0.7946

Epoch 00019: val_acc did not improve from 0.81290
Epoch 20/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3843 - acc: 0.8649 - val_loss: 0.6613 - val_acc: 0.7928

Epoch 00020: val_acc did not improve from 0.81290
Epoch 21/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3757 - acc: 0.8681 - val_loss: 0.6050 - val_acc: 0.8046

Epoch 00021: val_acc did not improve from 0.81290
Epoch 22/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3660 - acc: 0.8714 - val_loss: 0.6098 - val_acc: 0.7985

Epoch 00022: val_acc did not improve from 0.81290
Epoch 23/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3591 - acc: 0.8745 - val_loss: 0.6223 - val_acc: 0.8003

Epoch 00023: val_acc did not improve from 0.81290
Epoch 24/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3511 - acc: 0.8755 - val_loss: 0.8018 - val_acc: 0.7572

Epoch 00024: val_acc did not improve from 0.81290
Epoch 25/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3451 - acc: 0.8792 - val_loss: 0.6837 - val_acc: 0.7923

Epoch 00025: val_acc did not improve from 0.81290
Epoch 26/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3372 - acc: 0.8822 - val_loss: 0.6177 - val_acc: 0.8064

Epoch 00026: val_acc did not improve from 0.81290
Epoch 27/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3320 - acc: 0.8829 - val_loss: 0.6182 - val_acc: 0.7999

Epoch 00027: val_acc did not improve from 0.81290
Epoch 28/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3188 - acc: 0.8871 - val_loss: 0.6517 - val_acc: 0.7960

Epoch 00028: val_acc did not improve from 0.81290
Epoch 29/50
390/390 [==============================] - 30s 76ms/step - loss: 0.3225 - acc: 0.8862 - val_loss: 0.6076 - val_acc: 0.8142

Epoch 00029: val_acc improved from 0.81290 to 0.81420, saving model to /content/best_weights.hdf5
Epoch 30/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3196 - acc: 0.8877 - val_loss: 0.5671 - val_acc: 0.8134

Epoch 00030: val_acc did not improve from 0.81420
Epoch 31/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3065 - acc: 0.8909 - val_loss: 0.5963 - val_acc: 0.8136

Epoch 00031: val_acc did not improve from 0.81420
Epoch 32/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3056 - acc: 0.8918 - val_loss: 0.6097 - val_acc: 0.8120

Epoch 00032: val_acc did not improve from 0.81420
Epoch 33/50
390/390 [==============================] - 29s 76ms/step - loss: 0.3011 - acc: 0.8937 - val_loss: 0.6196 - val_acc: 0.8025

Epoch 00033: val_acc did not improve from 0.81420
Epoch 34/50
390/390 [==============================] - 29s 76ms/step - loss: 0.2890 - acc: 0.8975 - val_loss: 0.6057 - val_acc: 0.8183

Epoch 00034: val_acc improved from 0.81420 to 0.81830, saving model to /content/best_weights.hdf5
Epoch 35/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2877 - acc: 0.8984 - val_loss: 0.7143 - val_acc: 0.7941

Epoch 00035: val_acc did not improve from 0.81830
Epoch 36/50
390/390 [==============================] - 29s 75ms/step - loss: 0.2858 - acc: 0.8985 - val_loss: 0.6755 - val_acc: 0.7977

Epoch 00036: val_acc did not improve from 0.81830
Epoch 37/50
390/390 [==============================] - 29s 75ms/step - loss: 0.2829 - acc: 0.8988 - val_loss: 0.7908 - val_acc: 0.7713

Epoch 00037: val_acc did not improve from 0.81830
Epoch 38/50
390/390 [==============================] - 29s 76ms/step - loss: 0.2732 - acc: 0.9028 - val_loss: 0.6195 - val_acc: 0.8124

Epoch 00038: val_acc did not improve from 0.81830
Epoch 39/50
390/390 [==============================] - 29s 76ms/step - loss: 0.2700 - acc: 0.9041 - val_loss: 0.7104 - val_acc: 0.7905

Epoch 00039: val_acc did not improve from 0.81830
Epoch 40/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2683 - acc: 0.9046 - val_loss: 0.6636 - val_acc: 0.7996

Epoch 00040: val_acc did not improve from 0.81830
Epoch 41/50
390/390 [==============================] - 29s 75ms/step - loss: 0.2599 - acc: 0.9088 - val_loss: 0.5922 - val_acc: 0.8203

Epoch 00041: val_acc improved from 0.81830 to 0.82030, saving model to /content/best_weights.hdf5
Epoch 42/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2661 - acc: 0.9058 - val_loss: 0.5709 - val_acc: 0.8273

Epoch 00042: val_acc improved from 0.82030 to 0.82730, saving model to /content/best_weights.hdf5
Epoch 43/50
390/390 [==============================] - 29s 75ms/step - loss: 0.2576 - acc: 0.9065 - val_loss: 0.6646 - val_acc: 0.8030

Epoch 00043: val_acc did not improve from 0.82730
Epoch 44/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2548 - acc: 0.9097 - val_loss: 0.6797 - val_acc: 0.8032

Epoch 00044: val_acc did not improve from 0.82730
Epoch 45/50
390/390 [==============================] - 29s 76ms/step - loss: 0.2523 - acc: 0.9099 - val_loss: 0.6980 - val_acc: 0.8035

Epoch 00045: val_acc did not improve from 0.82730
Epoch 46/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2429 - acc: 0.9133 - val_loss: 0.5845 - val_acc: 0.8283

Epoch 00046: val_acc improved from 0.82730 to 0.82830, saving model to /content/best_weights.hdf5
Epoch 47/50
390/390 [==============================] - 29s 76ms/step - loss: 0.2474 - acc: 0.9114 - val_loss: 0.6655 - val_acc: 0.8131

Epoch 00047: val_acc did not improve from 0.82830
Epoch 48/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2401 - acc: 0.9153 - val_loss: 0.6603 - val_acc: 0.8098

Epoch 00048: val_acc did not improve from 0.82830
Epoch 49/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2416 - acc: 0.9142 - val_loss: 0.6708 - val_acc: 0.8066

Epoch 00049: val_acc did not improve from 0.82830
Epoch 50/50
390/390 [==============================] - 30s 76ms/step - loss: 0.2358 - acc: 0.9153 - val_loss: 0.5687 - val_acc: 0.8324

Epoch 00050: val_acc improved from 0.82830 to 0.83240, saving model to /content/best_weights.hdf5
Model took 1485.89 seconds to train
```
